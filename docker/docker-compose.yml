version: "3.7"

services:
  # --- Các service ứng dụng của bạn ---
  consul:
    container_name: consul
    image: hashicorp/consul:latest
    ports:
      - "8500:8500"
    restart: on-failure
    logging: &default-logging # Dùng anchor để tái sử dụng
      driver: "gelf"
      options:
        gelf-address: "udp://localhost:12201"
        tag: "{{.Name}}" # Tự động lấy tên container làm tag
    networks:
      - app-net

  orderdb:
    container_name: orderdb
    image: debezium/postgres:11
    platform: ${PLATFORM:-linux/amd64}
    ports:
      - "5432:5432"
    environment: &pg-env # Dùng anchor cho env
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  customerdb:
    container_name: customerdb
    image: debezium/postgres:11
    platform: ${PLATFORM:-linux/amd64}
    ports:
      - "5433:5432"
    environment: *pg-env
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  inventorydb:
    container_name: inventorydb
    image: debezium/postgres:11
    platform: ${PLATFORM:-linux/amd64}
    ports:
      - "5434:5432"
    environment: *pg-env
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  broker:
    image: confluentinc/cp-server:7.5.0
    platform: ${PLATFORM:-linux/amd64}
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENERS: "PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  connect:
    image: confluentinc/cp-kafka-connect:7.5.0
    platform: ${PLATFORM:-linux/amd64}
    hostname: connect
    container_name: connect
    depends_on:
      - broker
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "broker:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.5.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
    command:
      "bash -c 'confluent-hub install --no-prompt debezium/debezium-connector-postgresql:latest && confluent-hub install --no-prompt jcustenborder/kafka-connect-transform-common:latest && /etc/confluent/docker/run'"
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.0
    platform: ${PLATFORM:-linux/amd64}
    hostname: control-center
    container_name: control-center
    depends_on:
      - broker
      - connect
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: "broker:29092"
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: "connect:8083"
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: "/connectors"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021
    restart: on-failure
    logging: *default-logging
    networks:
      - app-net

  # --- Stack Logging (ELK) ---
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.7.1
    container_name: elasticsearch
    environment:
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    restart: on-failure
    networks:
      - monitoring-net

  logstash:
    image: docker.elastic.co/logstash/logstash:8.7.1
    container_name: logstash
    environment:
      LS_JAVA_OPTS: "-Xms512m -Xmx512m"
    ports:
      - "5044:5044"
      - "9600:9600"
      - "12201:12201/udp"
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
    restart: on-failure
    networks:
      - monitoring-net

  kibana:
    image: docker.elastic.co/kibana/kibana:8.7.1
    container_name: kibana
    environment:
      ELASTICSEARCH_HOSTS: 'http://elasticsearch:9200'
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: on-failure
    networks:
      - monitoring-net

  # --- Stack Monitoring (Prometheus + Grafana) ---
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.7.0
    container_name: kafka-exporter
    command: "--kafka.server=broker:29092"
    depends_on:
      - broker
    restart: on-failure
    networks:
      - app-net
      - monitoring-net

  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:postgres@orderdb:5432/postgres?sslmode=disable,postgresql://postgres:postgres@customerdb:5432/postgres?sslmode=disable,postgresql://postgres:postgres@inventorydb:5432/postgres?sslmode=disable"
    depends_on:
      - orderdb
      - customerdb
      - inventorydb
    restart: on-failure
    networks:
      - app-net
      - monitoring-net

  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: '--config.file=/etc/prometheus/prometheus.yml'
    restart: on-failure
    networks:
      - monitoring-net

  grafana:
    image: grafana/grafana:9.5.1
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    restart: on-failure
    networks:
      - monitoring-net

# --- Định nghĩa Networks và Volumes ---
networks:
  app-net:
    driver: bridge
  monitoring-net:
    driver: bridge

volumes:
  esdata:
    driver: local
